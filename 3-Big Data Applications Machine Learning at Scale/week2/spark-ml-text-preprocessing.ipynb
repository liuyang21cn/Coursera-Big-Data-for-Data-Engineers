{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(appName = \"test-app-trofim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "! echo $PYSPARK_SUBMIT_ARGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.Builder().getOrCreate() # required for dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "inputDF = spark.createDataFrame([(0, \"This is an apple. An apple is a fruit, not a vegetable\"),\n",
    "                                 (1, \"Fruits are tasty\"),\n",
    "                                 (2, \"Vegetables are nasty\")],\n",
    "                                  [\"id\", \"document\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol = \"document\", outputCol = \"words\")\n",
    "\n",
    "tokenizedDF = tokenizer.transform(inputDF)\n",
    "tokenizedDF.select('id', 'document').show(truncate = False)\n",
    "tokenizedDF.select('id', 'words').show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol = \"document\", outputCol = \"words\", pattern = \"\\\\s+|,|\\\\.\")\n",
    "\n",
    "tokenizedDF = regexTokenizer.transform(inputDF)\n",
    "tokenizedDF.select('id', 'document').show(truncate = False)\n",
    "tokenizedDF.select('id', 'words').show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stopwordsRemover = StopWordsRemover(inputCol = \"words\", outputCol = \"words_filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print stopwordsRemover.loadDefaultStopWords('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "removedDF = stopwordsRemover.transform(tokenizedDF)\n",
    "removedDF.show(truncate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "removedDF.select(\"document\", \"words_filtered\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import NGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ngram = NGram(n = 2, inputCol = \"words\", outputCol = \"ngrams\")  # bigram\n",
    "ngramDF = ngram.transform(removedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "row = ngramDF.select(\"document\", \"ngrams\").collect()[0]\n",
    "\n",
    "print row['document']\n",
    "print row['ngrams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "row = ngramDF.select(\"document\", \"ngrams\").collect()[1]\n",
    "\n",
    "print row['document']\n",
    "print row['ngrams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ngram = NGram(n = 3, inputCol = \"words\", outputCol = \"ngrams\")  # trigram\n",
    "ngramDF = ngram.transform(removedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "row = ngramDF.select(\"document\", \"ngrams\").collect()[0]\n",
    "\n",
    "print row['document']\n",
    "print row['ngrams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "row = ngramDF.select(\"document\", \"ngrams\").collect()[1]\n",
    "\n",
    "print row['document']\n",
    "print row['ngrams']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## TF * IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer    # implemented as an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#countVectorizer = CountVectorizer(inputCol = \"words_filtered\", outputCol = \"features_tf\", vocabSize = 2)\n",
    "countVectorizer = CountVectorizer(inputCol = \"words_filtered\", outputCol = \"features_tf\") \n",
    "model = countVectorizer.fit(removedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print model.vocabulary\n",
    "print len(model.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "countDF = model.transform(removedDF)\n",
    "row = countDF.collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print row['document']\n",
    "print row['words_filtered']\n",
    "print row['features_tf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "type(row['features_tf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "v = row['features_tf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "v.toArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF  # implemented as an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "idf = IDF(inputCol = \"features_tf\", outputCol = \"features_tf_idf\")\n",
    "idfModel = idf.fit(countDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "featuresDF = idfModel.transform(countDF)\n",
    "featuresDF.select(\"id\", \"document\").show(truncate = False)\n",
    "featuresDF.select(\"id\", \"features_tf_idf\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "row = featuresDF.collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print row['document']\n",
    "print row['words_filtered']\n",
    "print row['features_tf']\n",
    "print row['features_tf_idf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "catDF = spark.createDataFrame([\n",
    "    (0, \"New York\"),\n",
    "    (1, \"Moscow\"),\n",
    "    (2, \"Beijing\"),\n",
    "    (3, \"New York\"),\n",
    "    (4, \"Paris\"),\n",
    "    (5, \"Paris\"),\n",
    "    (6, \"New York\"),\n",
    "    (7, \"Beijing\")],\n",
    "    [\"row_id\", \"city\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------+\n",
      "|row_id|    city|cityIndex|\n",
      "+------+--------+---------+\n",
      "|     0|New York|      0.0|\n",
      "|     1|  Moscow|      3.0|\n",
      "|     2| Beijing|      1.0|\n",
      "|     3|New York|      0.0|\n",
      "|     4|   Paris|      2.0|\n",
      "|     5|   Paris|      2.0|\n",
      "|     6|New York|      0.0|\n",
      "|     7| Beijing|      1.0|\n",
      "+------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stringIndexer = StringIndexer(inputCol = \"city\", outputCol = \"cityIndex\")\n",
    "model = stringIndexer.fit(catDF)\n",
    "indexedDF = model.transform(catDF)\n",
    "\n",
    "indexedDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------+-------------+\n",
      "|row_id|    city|cityIndex|      cityVec|\n",
      "+------+--------+---------+-------------+\n",
      "|     0|New York|      0.0|(4,[0],[1.0])|\n",
      "|     1|  Moscow|      3.0|(4,[3],[1.0])|\n",
      "|     2| Beijing|      1.0|(4,[1],[1.0])|\n",
      "|     3|New York|      0.0|(4,[0],[1.0])|\n",
      "|     4|   Paris|      2.0|(4,[2],[1.0])|\n",
      "|     5|   Paris|      2.0|(4,[2],[1.0])|\n",
      "|     6|New York|      0.0|(4,[0],[1.0])|\n",
      "|     7| Beijing|      1.0|(4,[1],[1.0])|\n",
      "+------+--------+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder(inputCol = \"cityIndex\", outputCol = \"cityVec\")\n",
    "encoder.setDropLast(False)\n",
    "encodedDF = encoder.transform(indexedDF)\n",
    "encodedDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = encodedDF.collect()[0]\n",
    "row['cityVec'].toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  1.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = encodedDF.collect()[1]\n",
    "row['cityVec'].toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "catDF = spark.createDataFrame([\n",
    "    (0, \"New York\", \"books\"),\n",
    "    (1, \"Moscow\", \"moovies\"),\n",
    "    (2, \"Beijing\", \"clothes\"),\n",
    "    (3, \"Ney York\", \"clothes\"),\n",
    "    (4, \"Paris\", \"books\"),\n",
    "    (5, \"Paris\", \"electronics\"),\n",
    "    (6, \"New York\", \"electronics\"),\n",
    "    (7, \"Beijing\", \"moovies\")],\n",
    "    [\"row_id\", \"city\", \"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCol = \"city\", outputCol = \"cityIndex\")\n",
    "model = stringIndexer.fit(catDF)\n",
    "indexedDF = model.transform(catDF)\n",
    "\n",
    "stringIndexer2 = StringIndexer(inputCol = \"category\", outputCol = \"categoryIndex\")\n",
    "model2 = stringIndexer2.fit(indexedDF)\n",
    "indexedDF2 = model2.transform(indexedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---------+-------------+-------------+-------------+\n",
      "|city    |category   |cityIndex|categoryIndex|cityVec      |categoryVec  |\n",
      "+--------+-----------+---------+-------------+-------------+-------------+\n",
      "|New York|books      |2.0      |0.0          |(5,[2],[1.0])|(4,[0],[1.0])|\n",
      "|Moscow  |moovies    |3.0      |2.0          |(5,[3],[1.0])|(4,[2],[1.0])|\n",
      "|Beijing |clothes    |0.0      |1.0          |(5,[0],[1.0])|(4,[1],[1.0])|\n",
      "|Ney York|clothes    |4.0      |1.0          |(5,[4],[1.0])|(4,[1],[1.0])|\n",
      "|Paris   |books      |1.0      |0.0          |(5,[1],[1.0])|(4,[0],[1.0])|\n",
      "|Paris   |electronics|1.0      |3.0          |(5,[1],[1.0])|(4,[3],[1.0])|\n",
      "|New York|electronics|2.0      |3.0          |(5,[2],[1.0])|(4,[3],[1.0])|\n",
      "|Beijing |moovies    |0.0      |2.0          |(5,[0],[1.0])|(4,[2],[1.0])|\n",
      "+--------+-----------+---------+-------------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder(inputCol = \"cityIndex\", outputCol = \"cityVec\")\n",
    "encoder.setDropLast(False)\n",
    "encodedDF = encoder.transform(indexedDF2)\n",
    "\n",
    "encoder2 = OneHotEncoder(inputCol = \"categoryIndex\", outputCol = \"categoryVec\")\n",
    "encoder2.setDropLast(False)\n",
    "encodedDF2 = encoder2.transform(encodedDF)\n",
    "encodedDF2.select('city', 'category', 'cityIndex', 'categoryIndex', 'cityVec', 'categoryVec').show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols = [\"cityVec\", \"categoryVec\"],\n",
    "    outputCol = \"totalVec\")\n",
    "\n",
    "finalDF = assembler.transform(encodedDF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------------+-------------+-------------------+\n",
      "|    city|   category|      cityVec|  categoryVec|           totalVec|\n",
      "+--------+-----------+-------------+-------------+-------------------+\n",
      "|New York|      books|(5,[2],[1.0])|(4,[0],[1.0])|(9,[2,5],[1.0,1.0])|\n",
      "|  Moscow|    moovies|(5,[3],[1.0])|(4,[2],[1.0])|(9,[3,7],[1.0,1.0])|\n",
      "| Beijing|    clothes|(5,[0],[1.0])|(4,[1],[1.0])|(9,[0,6],[1.0,1.0])|\n",
      "|Ney York|    clothes|(5,[4],[1.0])|(4,[1],[1.0])|(9,[4,6],[1.0,1.0])|\n",
      "|   Paris|      books|(5,[1],[1.0])|(4,[0],[1.0])|(9,[1,5],[1.0,1.0])|\n",
      "|   Paris|electronics|(5,[1],[1.0])|(4,[3],[1.0])|(9,[1,8],[1.0,1.0])|\n",
      "|New York|electronics|(5,[2],[1.0])|(4,[3],[1.0])|(9,[2,8],[1.0,1.0])|\n",
      "| Beijing|    moovies|(5,[0],[1.0])|(4,[2],[1.0])|(9,[0,7],[1.0,1.0])|\n",
      "+--------+-----------+-------------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalDF.select('city', 'category', 'cityVec', 'categoryVec', 'totalVec').show(truncate = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Feature Interactions - not supported in python interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    ":(((((( ;(( ^_^"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
